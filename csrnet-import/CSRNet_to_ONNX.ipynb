{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPIfO4XlFlNe",
        "outputId": "5ce78171-1e51-4e2e-ce16-7c7a77c06596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9hu2N_zEh-S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "import h5py\n",
        "import torch\n",
        "import shutil\n",
        "\n",
        "def save_net(fname, net):\n",
        "    with h5py.File(fname, 'w') as h5f:\n",
        "        for k, v in net.state_dict().items():\n",
        "            h5f.create_dataset(k, data=v.cpu().numpy())\n",
        "def load_net(fname, net):\n",
        "    with h5py.File(fname, 'r') as h5f:\n",
        "        for k, v in net.state_dict().items():\n",
        "            param = torch.from_numpy(np.asarray(h5f[k]))\n",
        "            v.copy_(param)\n",
        "\n",
        "def save_checkpoint(state, is_best,task_id, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, task_id+filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(task_id+filename, task_id+'model_best.pth.tar')\n",
        "\n",
        "class CSRNet(nn.Module):\n",
        "    def __init__(self, load_weights=False):\n",
        "        super(CSRNet, self).__init__()\n",
        "        self.seen = 0\n",
        "        self.frontend_feat = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512]\n",
        "        self.backend_feat  = [512, 512, 512,256,128,64]\n",
        "        self.frontend = make_layers(self.frontend_feat)\n",
        "        self.backend = make_layers(self.backend_feat,in_channels = 512,dilation = True)\n",
        "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
        "        if not load_weights:\n",
        "            mod = models.vgg16(pretrained = True)\n",
        "            self._initialize_weights()\n",
        "            for i in xrange(len(self.frontend.state_dict().items())):\n",
        "                self.frontend.state_dict().items()[i][1].data[:] = mod.state_dict().items()[i][1].data[:]\n",
        "    def forward(self,x):\n",
        "        x = self.frontend(x)\n",
        "        x = self.backend(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.normal_(m.weight, std=0.01)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
        "    if dilation:\n",
        "        d_rate = 2\n",
        "    else:\n",
        "        d_rate = 1\n",
        "    layers = []\n",
        "    for v in cfg:\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate,dilation = d_rate)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    return nn.Sequential(*layers)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def xrange(x):\n",
        "  return range(x)\n",
        "\n",
        "checkpoint = torch.load('/content/drive/MyDrive/CSRNet/PartAmodel_best.pth.tar', map_location=torch.device('cpu'))\n"
      ],
      "metadata": {
        "id": "mEUgDlMzFJbT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CSRNet(load_weights=True)"
      ],
      "metadata": {
        "id": "pJigmIVpG5gg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(checkpoint['state_dict'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7r8ZqjqbHiq1",
        "outputId": "2c66c73d-4741-4452-a463-b1e657b3d139"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEsfoqgDJEOf",
        "outputId": "1539f2e2-aa1b-4917-fac4-98ecb97d7365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.7.1)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.onnx\n",
        "import torchvision.transforms.functional as F\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "aUYITTh5IwV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test the model -- prepare an image input and feed it through the model\n",
        "path = '/content/drive/MyDrive/CSRNet/IMG_4.jpg'\n",
        "img = Image.open(path)\n",
        "w,h = img.size\n",
        "img = img.resize((int(round(w * 9 // 10)), int(round(h * 9 // 10))))\n",
        "img = 255.0 * F.to_tensor(img.convert('RGB'))\n",
        "img[0,:,:]=img[0,:,:]-92.8207477031\n",
        "img[1,:,:]=img[1,:,:]-95.2757037428\n",
        "img[2,:,:]=img[2,:,:]-104.877445883\n",
        "#img = img.cuda()\n",
        "tensor = img.unsqueeze(0)\n",
        "output = model(tensor)\n",
        "output = output.detach().cpu().sum().numpy()\n",
        "\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYBRxfd8WQNF",
        "outputId": "8cd5b43a-0c32-44df-a92b-3e5c3eb2bc91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4286.402\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create an example input\n",
        "example_input = tensor\n",
        "\n",
        "# Step 3: Trace the model\n",
        "# Use torch.jit.trace to trace the model with the example input\n",
        "traced_model = torch.jit.trace(model, example_input)\n",
        "\n",
        "# Step 4: Export to ONNX format\n",
        "# Replace 'path_to_save.onnx' with the desired path to save the ONNX model file\n",
        "torch.onnx.export(traced_model, example_input, '/content/drive/MyDrive/CSRNet/csrnet.onnx', opset_version=11)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9gfzcNhWpxf",
        "outputId": "7f2b003c-081a-4c9e-e818-6bda3b6cc165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:825: UserWarning: no signature found for <torch.ScriptMethod object at 0x7e7a3cb6a070>, skipping _decide_input_format\n",
            "  warnings.warn(f\"{e}, skipping _decide_input_format\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
            "verbose: False, log level: Level.ERROR\n",
            "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
            "\n"
          ]
        }
      ]
    }
  ]
}